{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projet_Final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIKevin/Sentence_Classification_for_PGN/blob/master/Projet_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsvP6Q5gM6ma",
        "colab_type": "text"
      },
      "source": [
        "#Sentence Classification for Pointer Generator Network\n",
        "\n",
        "For this notebook you will need:\n",
        "\n",
        "\n",
        "1.   One dataset of annotated data with the class of the sentence (important or non-important)\n",
        "2.   One folder with csv files containing sentences to classify before making the raw data for the Pointer Generator Network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYlYQ9lCVKjY",
        "colab_type": "code",
        "outputId": "73c1881b-4c54-410b-a8fe-475ac98bb96f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51lVGkeXBd3O",
        "colab_type": "code",
        "outputId": "189a49d5-893d-41a0-9b8f-60c3f3cc8243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-beta1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/53/e18c5e7a2263d3581a979645a185804782e59b8e13f42b9c3c3cfb5bb503/tensorflow_gpu-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (348.9MB)\n",
            "\u001b[K     |████████████████████████████████| 348.9MB 58kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.16.4)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow-gpu==2.0.0-beta1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (3.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.33.4)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow-gpu==2.0.0-beta1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 32.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-beta1) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta1) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (3.1.1)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-gpu-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnJMpYiZSlL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import io\n",
        "import keras.preprocessing.text\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix as cm\n",
        "from sklearn.metrics import multilabel_confusion_matrix as mcm\n",
        "tf.keras.backend.clear_session()\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "pd.options.display.max_colwidth = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XblC8zbTyDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhtbrxuM_hfj",
        "colab_type": "text"
      },
      "source": [
        "#Data Preprocess\n",
        "For this part you will need:\n",
        "\n",
        "\n",
        "1.   Raw dataset of sentences (xlsx format)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyRx8GqZT5wZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(TRAIN_DATA_PATH):\n",
        "  #TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
        "\n",
        "  train_file_path = pd.read_excel(TRAIN_DATA_PATH, sep=';', encoding='latin-1', header=0)\n",
        "  msk = np.random.rand(len(train_file_path)) < 0.8\n",
        "\n",
        "  train = train_file_path[msk]\n",
        "\n",
        "  test = train_file_path[~msk]\n",
        "  #print(train_file_path.head)\n",
        "  all_data = np.array(train_file_path.values.tolist())\n",
        "  training_set = np.array(train.values.tolist())\n",
        "  test_set=np.array(test.values.tolist())\n",
        "  print(\"Dataset Length: \",len(training_set)+ len(test_set))\n",
        "  return all_data, training_set, test_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPajYlPlWD4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer(dataset):\n",
        "  # create the tokenizer\n",
        "  tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token='UNK')\n",
        "  # fit the tokenizer on the documents\n",
        "  tokenizer.fit_on_texts(all_data[:,1])\n",
        "  # summarize what was learned\n",
        "  print(\"Word counter: \",tokenizer.word_counts)\n",
        "  print(\"Number of sentences: \",tokenizer.document_count)\n",
        "  print(\"Word Index: \", tokenizer.word_index)\n",
        "  print(\"Word Docs: \",tokenizer.word_docs)\n",
        "  return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FC8jHEqrf4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reverser():\n",
        "  reverse_word_index = dict([(value, key) for (key, value) in tokenizer.word_index.items()])\n",
        "  return reverse_word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGO4gQR9uqrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vocab_size(tokenizer):\n",
        "  vocab_size=len(tokenizer.word_counts)+2\n",
        "  return vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDX-rPlzryh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maxlen(training, test):\n",
        "  max_train_sequence_len = max([len(x) for x in training])\n",
        "  max_test_sequence_len = max([len(x) for x in test])\n",
        "  return max(max_train_sequence_len, max_test_sequence_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPjTzYJiUOo_",
        "colab_type": "code",
        "outputId": "a06a8f79-89bb-4d34-fa69-23fafd2b4b1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_data, training_set, test_set = create_dataset(\"/content/drive/My Drive/Datasets/donnee4.xlsx\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Length:  2398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lie-ExIoWz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer=create_tokenizer(all_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77MYhEByADca",
        "colab_type": "text"
      },
      "source": [
        "#Embeddings pretraining (Next Word Prediction)\n",
        "For this part you will need:\n",
        "\n",
        "\n",
        "1.   Preprocessed dataset\n",
        "2.   Tokenizer from the data preprocess part\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5FSota9ocYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_and_split_sentences(input_set):\n",
        "  input_sequences = []\n",
        "  for line in input_set[:,1]:\n",
        "      token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "      for i in range(1, len(token_list)):\n",
        "          n_gram_sequence = token_list[:i+1]\n",
        "          input_sequences.append(n_gram_sequence)\n",
        "  return input_sequences\n",
        "  #print(input_test_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr6EnLLJCRyk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR4TT-NXu6qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sentences(input_sequences, max_sequence_len):\n",
        "  input_padded_sequences = np.array(pad_sequences(input_sequences,   \n",
        "                            maxlen=max_sequence_len, padding='pre'))\n",
        "  return input_padded_sequences\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNQSBUz74pzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset_slices(input_sequences):\n",
        "  predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "  label = keras.utils.to_categorical(label, num_classes=vocab_size)\n",
        "  return predictors, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGnrFQwt8Wvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_preprocessed_dataset(predictors, labels):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((predictors, labels))\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jn1u0hm9PMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_train_dataset(train_dataset, BUFFER_SIZE, BATCH_SIZE):\n",
        "  train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "  train_dataset = train_dataset.padded_batch(BATCH_SIZE, train_dataset.output_shapes)\n",
        "  return train_dataset\n",
        "def prepare_test_dataset(test_dataset, BATCH_SIZE):\n",
        "  test_dataset = test_dataset.padded_batch(BATCH_SIZE, test_dataset.output_shapes)\n",
        "  return test_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Hyi3eCC7PU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top_k_categorical_accuracy2(y_true, y_pred, k=50):\n",
        "    return K.mean(K.in_top_k(K.cast(y_pred,dtype='float32'), K.argmax(y_true, axis=-1), k), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwbcV72OWHIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(model):\n",
        "  e = model.layers[0]\n",
        "  weights = e.get_weights()[0]\n",
        "  return weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em7kGeJzmsb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_tsv_for_visualization(weights):\n",
        "  out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "  out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "  for word_num in range(vocab_size):\n",
        "    if word_num==0:\n",
        "      word = \"PAD\"\n",
        "      embeddings = weights[word_num]\n",
        "    else:\n",
        "      reverse_word_index=reverser()\n",
        "      word = reverse_word_index[word_num]\n",
        "      embeddings = weights[word_num]\n",
        "    out_m.write(word + \"\\n\")\n",
        "    out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "  out_v.close()\n",
        "  out_m.close()\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N_TUoesrXWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_train=tokenize_and_split_sentences(training_set)\n",
        "input_test=tokenize_and_split_sentences(test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCVXzcrru3ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size=vocab_size(tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kvjSsa51BMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_sequence_len=maxlen(input_train,input_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT-0Wj_z4VS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_training_sequences=pad_sentences(input_train, max_sequence_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dlvjWX84mpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_test_sequences=pad_sentences(input_test, max_sequence_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npBzzNCa7002",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_predictors, training_label=create_dataset_slices(input_training_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQvSbg2b79Bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictors, test_label= create_dataset_slices(input_test_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7Bmz5iG8F6V",
        "colab_type": "code",
        "outputId": "8b74ce0d-67eb-4f3e-9b27-38daa55e9128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(len(training_predictors))\n",
        "print(len(test_predictors))\n",
        "print(len(test_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56716\n",
            "15433\n",
            "15433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk_0f3Ez888n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset=create_preprocessed_dataset(training_predictors,training_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWu9K13F9B4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset=create_preprocessed_dataset(test_predictors,test_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jIcKyc0BP0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av5PVx5CApNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset=prepare_train_dataset(train_dataset, BUFFER_SIZE, BATCH_SIZE)\n",
        "test_dataset= prepare_test_dataset(test_dataset, BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1D0oK1OBBu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 64),\n",
        "    tf.keras.layers.LSTM(150),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBOqGuCbC9j2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[top_k_categorical_accuracy2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oScJC7VqC_kx",
        "colab_type": "code",
        "outputId": "d5cf1b3b-adaf-4767-eba8-09a67dd941ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "history = model.fit(train_dataset, epochs=10, validation_data=test_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0725 10:20:13.678402 140478070486912 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3545/3545 [==============================] - 366s 103ms/step - loss: 6.3503 - top_k_categorical_accuracy2: 0.4772 - val_loss: 5.9724 - val_top_k_categorical_accuracy2: 0.5190\n",
            "Epoch 2/10\n",
            "3545/3545 [==============================] - 366s 103ms/step - loss: 5.2940 - top_k_categorical_accuracy2: 0.5998 - val_loss: 5.2932 - val_top_k_categorical_accuracy2: 0.6274\n",
            "Epoch 3/10\n",
            "3545/3545 [==============================] - 369s 104ms/step - loss: 4.5952 - top_k_categorical_accuracy2: 0.6884 - val_loss: 4.9753 - val_top_k_categorical_accuracy2: 0.6684\n",
            "Epoch 4/10\n",
            "3545/3545 [==============================] - 368s 104ms/step - loss: 4.0940 - top_k_categorical_accuracy2: 0.7558 - val_loss: 4.8045 - val_top_k_categorical_accuracy2: 0.6945\n",
            "Epoch 5/10\n",
            "3545/3545 [==============================] - 365s 103ms/step - loss: 3.6928 - top_k_categorical_accuracy2: 0.8110 - val_loss: 4.7383 - val_top_k_categorical_accuracy2: 0.7058\n",
            "Epoch 6/10\n",
            "3545/3545 [==============================] - 365s 103ms/step - loss: 3.3538 - top_k_categorical_accuracy2: 0.8566 - val_loss: 4.6739 - val_top_k_categorical_accuracy2: 0.7128\n",
            "Epoch 7/10\n",
            "3545/3545 [==============================] - 365s 103ms/step - loss: 3.0641 - top_k_categorical_accuracy2: 0.8913 - val_loss: 4.6640 - val_top_k_categorical_accuracy2: 0.7155\n",
            "Epoch 8/10\n",
            "3545/3545 [==============================] - 371s 105ms/step - loss: 2.8167 - top_k_categorical_accuracy2: 0.9145 - val_loss: 4.6556 - val_top_k_categorical_accuracy2: 0.7184\n",
            "Epoch 9/10\n",
            "3545/3545 [==============================] - 366s 103ms/step - loss: 2.5793 - top_k_categorical_accuracy2: 0.9354 - val_loss: 4.6865 - val_top_k_categorical_accuracy2: 0.7190\n",
            "Epoch 10/10\n",
            "3545/3545 [==============================] - 375s 106ms/step - loss: 2.3657 - top_k_categorical_accuracy2: 0.9494 - val_loss: 4.6885 - val_top_k_categorical_accuracy2: 0.7235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snXGeo3YDBmo",
        "colab_type": "code",
        "outputId": "2a253be5-ce0b-4c07-a64c-29bc25957eea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF4VtY2Jk20s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w=get_embeddings(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq8P_9SLlAX6",
        "colab_type": "code",
        "outputId": "4eda55bd-2712-451e-aa61-f41b45285098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "w"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.372, -0.024,  0.111, ...,  0.03 , -0.024,  0.038],\n",
              "       [-0.018, -0.017, -0.047, ..., -0.003,  0.027, -0.012],\n",
              "       [ 0.091, -0.391, -0.015, ..., -0.043, -0.213,  0.098],\n",
              "       ...,\n",
              "       [ 0.288, -0.005, -0.006, ..., -0.146, -0.02 ,  0.028],\n",
              "       [-0.213,  0.043,  0.092, ..., -0.066, -0.184, -0.148],\n",
              "       [ 0.095,  0.113, -0.171, ...,  0.047,  0.039, -0.347]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8LhmhlTLEmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#write_tsv_for_visualization(w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYQ07FuYmgjk",
        "colab_type": "text"
      },
      "source": [
        "#Sentence Selection\n",
        "For this part you will need: \n",
        "\n",
        "1.   Pre-trained embeddings weights from the next word prediction\n",
        "2.   Dataset of the next word prediction model (training_set and test_set) OR raw data which needs to be preprocessed (cf next word prediction part)\n",
        "3.   Dataset of sentences to be classified\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5CANHpM8NE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_sentences(input_set):\n",
        "  input_sequences = []\n",
        "  for line in input_set[:,1]:\n",
        "      token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "      input_sequences.append(token_list)\n",
        "  return input_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEI_BY-dNLD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sentences2(input_sequences, max_sequence_len):\n",
        "  input_padded_sequences=[]\n",
        "  for line in input_sequences:\n",
        "    padded_sequences =padarray(line, max_sequence_len)\n",
        "    input_padded_sequences.append(padded_sequences)\n",
        "  return input_padded_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnZQ4K9nlA5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset_slices_sentence_classification(input_sequences, targets):\n",
        "  predictors= tf.constant(input_sequences)\n",
        "  targets=targets.astype(int)\n",
        "  nb_classes = 18\n",
        "  targets = targets.reshape(-1)\n",
        "  one_hot_targets = np.eye(nb_classes)[targets]\n",
        "  return predictors, one_hot_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTBizW1rlnZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padarray(A, size):\n",
        "    t = size - len(A)\n",
        "    return np.pad(A, pad_width=(0, t), mode='constant')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vMr6kx8t9p_9",
        "colab": {}
      },
      "source": [
        "def sample_predict(sentence, pad, t, model):\n",
        "  tokenized_sample_pred_text =t.texts_to_sequences([sentence])\n",
        "  tokenized_sample_pred_text=np.array(tokenized_sample_pred_text)\n",
        "  #print(len(tokenized_sample_pred_text[0]))     \n",
        "  PAD_SIZE=80  \n",
        "  if len(tokenized_sample_pred_text[0])<PAD_SIZE:\n",
        "    inp=padarray(tokenized_sample_pred_text[0], PAD_SIZE)\n",
        "    predictions = model.predict(tf.expand_dims(inp, 0)) \n",
        "    return np.argmax(predictions)\n",
        "  else:\n",
        "    return 17\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bcx_FlLM_FS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#emb= pd.read_csv(\"vecs.tsv\",sep='\\t',header=None)\n",
        "embeddings= np.array(w)\n",
        "def retemb(shape, dtype=None):\n",
        "  return embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNXCREqFKt4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset_PGN(folder_path, receiving_folder_path, add_score, tokenizer, model):\n",
        "  folder_name=os.listdir(folder_path)\n",
        "  num_match=0\n",
        "  for file in folder_name:    \n",
        "    i=0\n",
        "    raw=pd.read_excel(folder_path+str(file), sep=';', encoding='latin-1', header=None)\n",
        "    \n",
        "    #print(raw[0])\n",
        "    article=\"\"\n",
        "    for line in raw[0]:\n",
        "      #print(line)\n",
        "      if i==0:        \n",
        "        score= str(line)\n",
        "        print(\"score: \",score)\n",
        "      if i==1:        \n",
        "        summary= str(line)\n",
        "        print(\"summary: \", summary)\n",
        "      else:\n",
        "      #print(line)\n",
        "        predictions = sample_predict(str(line), True, tokenizer, model)\n",
        "        #print(np.argmax(predictions))\n",
        "        if predictions!=17:\n",
        "          article+= \" \"+ str(line) \n",
        "      i+=1\n",
        "    #print(summary)\n",
        "    #print(article)\n",
        "    resultat= score + article  +\"\\n\"+ \" @highlight \" +\"\\n\" + summary\n",
        "    #print(resultat)\n",
        "    with open(os.path.join(receiving_folder_path, \"match\"+str(num_match)+ \".story\"), 'w') as writer:\n",
        "      writer.write(resultat)\n",
        "      num_match+=1\n",
        "      \n",
        "    #print(resultat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIki0bCO-tk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_train2=tokenize_sentences(training_set)\n",
        "input_test2=tokenize_sentences(test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMu7Sx5c-zVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_training_sequences2=pad_sentences2(input_train2, max_sequence_len)\n",
        "input_test_sequences2=pad_sentences2(input_test2,max_sequence_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb-6Wv5H_6kw",
        "colab_type": "code",
        "outputId": "230154bc-4e06-41f7-f156-c0406c05614e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "input_training_sequences2[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1718, 2362,  326,  196,  563,    8,  189,  122,  435,   78,  843,\n",
              "         49,   32,    3,  656,  593,  688,   45, 1719, 2363,   21, 2364,\n",
              "          2,  688, 2365, 2366,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlOo3nEJ7NYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_predictors2, training_label2=create_dataset_slices_sentence_classification(input_training_sequences2,training_set[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myXa82nH7XaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictors2, test_label2=create_dataset_slices_sentence_classification(input_test_sequences2,test_set[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFYBS54f_9DU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset2=create_preprocessed_dataset(training_predictors2, training_label2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS2hrXFvET68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset2=create_preprocessed_dataset(test_predictors2, test_label2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCnp-i0bEvC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for features_tensor, target_tensor in train_dataset2:\n",
        "    print(f'features:{features_tensor} target:{target_tensor}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LMYGm9EE-Ca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset2=prepare_train_dataset(train_dataset2, BUFFER_SIZE, BATCH_SIZE)\n",
        "test_dataset2= prepare_test_dataset(test_dataset2, BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REYc-e90_NXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(18, activation='softmax')\n",
        "])\n",
        "#adam=tf.keras.optimizers.Adam(learning_rate=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZVEPIUu_PVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3PLLJza_RJO",
        "colab_type": "code",
        "outputId": "5af672fe-98c1-4573-c36e-e5b24d6f3890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "history = model.fit(train_dataset2, epochs=5, validation_data=test_dataset2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "118/118 [==============================] - 13s 109ms/step - loss: 1.5966 - accuracy: 0.4912 - val_loss: 1.2384 - val_accuracy: 0.6214\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 8s 70ms/step - loss: 1.0476 - accuracy: 0.6537 - val_loss: 1.0909 - val_accuracy: 0.6252\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 8s 70ms/step - loss: 0.8830 - accuracy: 0.7122 - val_loss: 1.1029 - val_accuracy: 0.6136\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 8s 70ms/step - loss: 0.7817 - accuracy: 0.7451 - val_loss: 1.1211 - val_accuracy: 0.6330\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 8s 70ms/step - loss: 0.7088 - accuracy: 0.7764 - val_loss: 1.2384 - val_accuracy: 0.6194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I_aHkIljVKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=model.predict(test_dataset2)\n",
        "y_pred=tf.keras.backend.argmax(y_pred)\n",
        "print((y_pred))\n",
        "targ=tf.keras.backend.argmax(test_label2)\n",
        "print(targ)\n",
        "print(classification_report(targ,y_pred))\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print('Test Loss: {}'.format(test_loss))\n",
        "print('Test Accuracy: {}'.format(test_acc))\n",
        "print(cm(targ,y_pred))\n",
        "print(mcm(targ,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpK9JYc7_Ygm",
        "colab_type": "code",
        "outputId": "630eae1a-abbf-466d-dc61-a18e96986d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_pred_text = 'Neymar marque un but'\n",
        "predictions = sample_predict(sample_pred_text, False, tokenizer, model)\n",
        "print (predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbAkAk9fN1iD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 64, embeddings_initializer=retemb),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(18, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmgeXwrkOF_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fzdx6EbXuBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ckpt=tf.keras.callbacks.ModelCheckpoint(\"/content/\", save_best_only=True,verbose=1, monitor='val_accuracy', mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crSYCG9POI1P",
        "colab_type": "code",
        "outputId": "250bd4af-8f11-4a08-e7ea-dcc8be6e5d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "history3 = model3.fit(train_dataset2, epochs=4,\n",
        "                    validation_data=test_dataset2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "118/118 [==============================] - 13s 112ms/step - loss: 1.4279 - accuracy: 0.5343 - val_loss: 1.1424 - val_accuracy: 0.6175\n",
            "Epoch 2/4\n",
            "118/118 [==============================] - 9s 75ms/step - loss: 1.0325 - accuracy: 0.6484 - val_loss: 1.0496 - val_accuracy: 0.6311\n",
            "Epoch 3/4\n",
            "118/118 [==============================] - 9s 74ms/step - loss: 0.9054 - accuracy: 0.6861 - val_loss: 1.0175 - val_accuracy: 0.6447\n",
            "Epoch 4/4\n",
            "118/118 [==============================] - 9s 75ms/step - loss: 0.7721 - accuracy: 0.7456 - val_loss: 1.0435 - val_accuracy: 0.6583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVOe6stnXRtE",
        "colab_type": "code",
        "outputId": "99bbe171-4117-4bc5-9283-4b11256a8bd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "history4 = model3.fit(train_dataset2, epochs=2,\n",
        "                    validation_data=test_dataset2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "118/118 [==============================] - 9s 74ms/step - loss: 0.6659 - accuracy: 0.7833 - val_loss: 1.1403 - val_accuracy: 0.6660\n",
            "Epoch 2/2\n",
            "118/118 [==============================] - 9s 77ms/step - loss: 0.5650 - accuracy: 0.8173 - val_loss: 1.1677 - val_accuracy: 0.6680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "azUJ6cejKnX8",
        "colab": {}
      },
      "source": [
        "y_pred=model3.predict(test_dataset2)\n",
        "y_pred=tf.keras.backend.argmax(y_pred)\n",
        "print((y_pred))\n",
        "targ=tf.keras.backend.argmax(test_label2)\n",
        "print(targ)\n",
        "print(classification_report(targ,y_pred))\n",
        "test_loss, test_acc = model3.evaluate(test_dataset2)\n",
        "print('Test Loss: {}'.format(test_loss))\n",
        "print('Test Accuracy: {}'.format(test_acc))\n",
        "print(cm(targ,y_pred))\n",
        "print(mcm(targ,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c9704e5b-88c3-41ba-c0d1-167db5c97763",
        "id": "NIypG4AfKnX_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_pred_text = 'Neymar marque un but'\n",
        "predictions = sample_predict(sample_pred_text, False, tokenizer, model3)\n",
        "print (predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYVbykj5n-uh",
        "colab_type": "code",
        "outputId": "13de7417-507f-4a9c-ca5c-be844b4cf0a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        }
      },
      "source": [
        "create_dataset_PGN(\"/content/drive/My Drive/Datasets/tout/\",\"/content/\", True, tokenizer, model3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score:  OM gagne le match contre Sochaux avec un score 2-1\n",
            "summary:  Face à une vaillante équipe de Sochaux, l'OM reprend goût à la victoire dans la douleur après 4 matches sans succès en L1 sur un penalty de Gignac, très contesté par les Doubistes. Marseille rejoint le top 5 tandis que Sochaux reste lanterne rouge.\n",
            "score:  Lyon gagne le match contre Saint-Etienne avec un score 2-1\n",
            "summary:  Lyon s'impose pour la 6e fois d'affilée en L1 à Geoffroy-Guichard grâce à un but de Briand dans les dernières secondes. Un scénario cruel pour Saint-Étienne qui avait parfaitement réagi après le premier but lyonnais mais doit s'incliner face à son rival.\n",
            "score:  Lyon fait match nul contre Valenciennes avec un score 1 - 1\n",
            "summary:  Lyon manque l'occasion de recoller aux premières places. Après deux victoires de suite en Ligue 1, les Rhodaniens concèdent un nul logique face une équipe de VA transfigurée en seconde période.\n",
            "score:  Valenciennes fait match nul contre Montpellier avec un score 1 - 1\n",
            "summary:  Cruelle fin de match pour Valenciennes qui laisse filer la victoire dans le temps additionnel sur un oubli défensif face à un MHSC courageux et pourtant réduit à dix. Un match nul qui n'arrange personne, surtout pas VA qui reste relégable.\n",
            "score:  Sochaux fait match nul contre Bastia avec un score 1 - 1\n",
            "summary:  L'arbitre met fin à cette rencontre perturbée par les mauvaises appréciations du corps arbitral. Les Sochaliens auront tout donné pour essayer de battre des Bastiais passés complètement au travers de la seconde période, mais sans réussite.\n",
            "score:  Nantes gagne le match contre Bordeaux avec un score 3-0\n",
            "summary:  Grâce à un réalisme à toute épreuve, Nantes s'offre Bordeaux dans le derby de l'Atlantique. Avec ce succès, les Canaris restent quatrièmes alors que les Girondins, qui n'ont pourtant pas démérité, subissent une deuxième défaite en trois jours. Dur.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-264-01c5ac03e9a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_dataset_PGN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Datasets/tout/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/content/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-263-f3bf640f13ef>\u001b[0m in \u001b[0;36mcreate_dataset_PGN\u001b[0;34m(folder_path, receiving_folder_path, add_score, tokenizer, model)\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;31m#print(line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m#print(np.argmax(predictions))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-143-6eb4f9ce598d>\u001b[0m in \u001b[0;36msample_predict\u001b[0;34m(sentence, pad, t, model)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sample_pred_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mPAD_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sample_pred_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPAD_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EvswJ0z4Dkb",
        "colab_type": "text"
      },
      "source": [
        "#What's Next?\n",
        "Now you have created your folder of .story files. Now you can follow the github of to preprocess this folder and start the training of the Pointer Generator Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENq88-wevN0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}